---
layout: post
title: "스파크 완벽 가이드 - 아파치 스파크란" 
author: Gunju Ko
categories: [hadoop]
cover:  "/assets/instacode.png"
---

> 이 글은 "스파크 완벽 가이드" 책 내용을 정리한 글입니다. 
>
> 저작권에 문제가 있는 경우 "gunjuko92@gmail.com"으로 연락주시면 감사하겠습니다.

# 스파크 완벽 가이드 - 아파치 스파크란

* 아파치 스파크란?
  * 통합 컴퓨팅 엔진
  * 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합
  * 병렬 처리 오픈소스 엔진
  * 파이썬, 자바, 스칼라, R를 지원
  * SQL, 스트리밍, 머시러닝 등 넓은 범위의 라이브러리를 제공
* 스파크 구성

![그림]({{ site.url }}/assets/img/posts/spark-guide/chapter1/photo1.png)

### 1 아파치 스파크의 철학

#### 통합

* 빅데이터 애플리케이션 개발에 필요한 통합 플랫폼을 제공하는것이 목표이다.
* 통합의 의미 : 스파크는 데이터 읽기, SQL 처리, 스트림 처리, 머신러닝 등 다양한 데이터 분석 작업을 같은 연산 엔진과 API로 수행할 수 있도록 설계
* 일관성 있는 조합형 API를 제공하므로 기존 라이브러리를 사용해 애플리케이션을 만들 수 있음

#### 컴퓨팅 엔진

* 스파크는 기능의 범위를 컴퓨팅 엔진으로 제한함
* 데이터를 연산하는 역할만 수행할 뿐 저장소 역할은 수행하지 않음
* 대신에 다양한 저장소를 지원 (아마존 S3, Hadoop, Kafka 등)
* 스파크는 데이터 저장 위치에 상관없이 처리에 집중하도록 만들어짐
* 사용자 API는 서로 다른 저장소 시스템을 매우 유사하게 볼 수 있도록 만들어졌음.

#### 라이브러리

* 데이터 분석 작업에 필요한 통합 API를 제공함
* 스파크는 엔진에서 제공하는 표준 라이브러리와 오픈소스 커뮤니티에서 서드파티 패키지 형태로 제공하는 다양한 외부 라이브러리를 지원함
* 스파크는 SQL, MLlib, 스파크 스트리밍, GraphX 등 다양한 라이브러리를 제공한다. 그 외 수백 개의 외부 오픈소스 라이브러리도 존재한다. 

### 2. 등장 배경

* 이전에는 대규모 데이터 처리를 프로세서의 성능 향상에 맡겼지만 하드웨어 성능 향상에는 한계가 있음
* 성능 향상을 위해선 병렬 처리가 필수적으로 필요함 + 데이터가 클러스터에서 처리해야 할 만큼 거대해짐 => 새로운  프로그래밍 모델이 필요해졌음

### 3. 스파크의 역사

* 전통적인 머신러닝 알고리즘은 데이터를 10~20회 가량 처리함 => 맵 리듀스로 처리하려면 단계별로 맵리듀스 잡을 개발하고 클러스터에서 각각 실행해야 하므로 매번 데이터를 처음부터 읽어야함
* 이런 문제를 해결하기 위해 여러 단계로 이루어진 애플리케이션을 간견하게 개발할 수 있는 함수형 프로그래밍 기반의 API를 설계함 그리고 연산 단계 사이에서 메모리에 저장된 데이터를 효율적으로 공유할 수 있는 새로운 엔진 기반의 API를 구현
* 스파크에서 대화형으로 SQL을 실행할 수 있는 엔진인 샤크를 개발
* MLlib, 스파크 스트리밍, GraphX를 만들기 시작 (같은 엔진을 이용해 여러 처리 유형을 결합)
* 2014년에 1.0 버전을 2016년에 2.0 버전을 공개

### 5. 스파크 실행하기

* 스파크는 스칼라로 구현되어 자바 가상 머신 기반으로 동작
* 로컬 환경에서도 실행 가능. 
* 하둡 클러스터에 접속하고 싶은 경우 하둡 버전에 맞는 패키지 유형을 선택해 올바른 버전을 내려받아야함.
* 다양한 언어를 지원하는 스파크의 대화형 셸을 제공함



